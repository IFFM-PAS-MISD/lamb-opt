Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Ye2018,
abstract = {For many decades, ultrasonic imaging inspection has been adopted as a principal method to detect multiple defects, e.g., void and corrosion. However, the data interpretation relies on an inspector's subjective judgment, thus making the results vulnerable to human error. Nowadays, advanced computer vision techniques reveal new perspectives on the high-level visual understanding of universal tasks. This research aims to develop an efficient automatic ultrasonic image analysis system for nondestructive testing (NDT) using the latest visual information processing technique. To this end, we first established an ultrasonic inspection image dataset containing 6849 ultrasonic scan images with full defect/no-defect annotations. Using the dataset, we performed a comprehensive experimental comparison of various computer vision techniques, including both conventional methods using hand-crafted visual features and the most recent convolutional neural networks (CNN) which generate multiple-layer stacking for representation learning. In the computer vision community, the two groups are referred to as shallow and deep learning, respectively. Experimental results make it clear that the deep learning-enabled system outperformed conventional (shallow) learning schemes by a large margin. We believe this benchmarking could be used as a reference for similar research dealing with automatic defect detection in ultrasonic imaging inspection.},
author = {Ye, Jiaxing and Ito, Shunya and Toyama, Nobuyuki},
doi = {10.3390/s18113820},
issn = {1424-8220},
journal = {Sensors},
keywords = {Computer vision,Convolutional neural networks,Deep learning,Local descriptor,Nondestructive evaluation,Ultrasonic imaging},
month = {nov},
number = {11},
pages = {3820},
title = {{Computerized Ultrasonic Imaging Inspection: From Shallow to Deep Learning}},
url = {http://www.mdpi.com/1424-8220/18/11/3820},
volume = {18},
year = {2018}
}
@article{Ewald2019b,
abstract = {In our previous work, we demonstrated how to use inductive bias to infuse a convolutional neural network (CNN) with domain knowledge from fatigue analysis for aircraft visual NDE. We would like to extend this concept to SHM and therefore in this paper, we present a novel framework called DeepSHM which involves data augmentation of captured sensor signals and formalizes a generic method for end-to-end deep learning for SHM. The study case is limited to ultrasonic guided waves SHM. The sensor signal response from a Finite-Element-Model (FEM) is pre-processed through wavelet transform to obtain the wavelet coefficient matrix (WCM), which is then fed into the CNN to be trained to obtain the neural weights. At the end of this paper, we also present the results of our investigation on CNN complexities that is needed to generalize the multitude variation of sensor signals based on experimental testing of the DeepSHM concept with Lamb wave experiment data from coupon testing.},
author = {Ewald, Vincentius and Groves, Roger M. and Benedictus, Rinze},
doi = {10.1117/12.2506794},
file = {::},
isbn = {9781510625952},
issn = {1996756X},
number = {February},
pages = {19},
title = {{DeepSHM: a deep learning approach for structural health monitoring based on guided Lamb wave technique}},
year = {2019}
}
